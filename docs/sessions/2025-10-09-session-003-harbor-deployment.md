# Session 003: Harbor Registry Deployment

  **Date**: 2025-10-09
  **Duration**: ~3 hours
  **Focus**: Deploy Harbor OCI registry with OpenShift-compatible configuration

  ## Objective

  Deploy Harbor as the internal container registry for the airgapped platform, with proper persistent storage, OpenShift Route, and TLS termination.

  ## Summary

  Successfully deployed Harbor registry after troubleshooting OpenShift Security Context Constraints (SCC) issues. Learned critical production skills including Helm chart customization, SCC troubleshooting, and
  OpenShift Route configuration.

  ## Work Completed

  ### 1. Helm Repository Setup

  Added Harbor Helm repository:
  ```bash
  helm repo add harbor https://helm.goharbor.io
  helm repo update
  helm search repo harbor/harbor

  Chart version deployed: 1.18.0 (Harbor 2.14.0)

  2. Values File Creation

  Created /root/platform-gitops/components/harbor/values-openshift.yaml:

  expose:
    type: clusterIP
    tls:
      enabled: false  # TLS handled at OpenShift Route
    clusterIP:
      name: harbor
      ports:
        httpPort: 80

  externalURL: https://harbor.apps.lab.ocp.lan

  persistence:
    enabled: true
    resourcePolicy: keep
    persistentVolumeClaim:
      registry:
        storageClass: nfs-harbor
        size: 50Gi
      database:
        storageClass: nfs-harbor
        size: 5Gi
      redis:
        storageClass: nfs-harbor
        size: 2Gi
      trivy:
        storageClass: nfs-harbor
        size: 5Gi

  harborAdminPassword: Harbor12345

  database:
    type: internal

  redis:
    type: internal

  trivy:
    enabled: true

  notary:
    enabled: false

  metrics:
    enabled: false

  Key decisions:
  - Disabled TLS at Harbor level (handled by OpenShift Route)
  - Used ClusterIP service type (not Ingress)
  - Allocated ~64Gi total storage (50Gi registry + 14Gi for DB/Redis/Trivy)

  3. Security Context Constraints (SCC) Troubleshooting

  Problem encountered:
  Harbor pods couldn't start due to OpenShift SCC restrictions:
  runAsUser: Invalid value: 10000: must be in the ranges: [1000760000, 1000769999]
  fsGroup: Invalid value: []int64{10000}: 10000 is not an allowed group

  Root cause:
  - Harbor's Helm chart designed for vanilla Kubernetes
  - OpenShift enforces stricter security with UID ranges per namespace
  - Harbor images hard-coded to run as UID 10000 and 999

  Solution:
  oc adm policy add-scc-to-user privileged -z default -n harbor

  Production learning:
  - anyuid SCC allows any UID (less restrictive)
  - privileged SCC needed due to seccomp profile conflicts
  - Alternative: Rebuild Harbor images with OpenShift-compatible UIDs (more secure, more complex)

  4. Harbor Deployment

  helm install harbor harbor/harbor \
    --namespace harbor \
    --values values-openshift.yaml \
    --timeout 10m

  Deployment verified:
  oc get pods -n harbor

  All 8 pods running:
  - harbor-core (API server)
  - harbor-database (PostgreSQL)
  - harbor-jobservice (background jobs)
  - harbor-nginx (reverse proxy)
  - harbor-portal (web UI)
  - harbor-redis (cache)
  - harbor-registry (image storage - 2 containers)
  - harbor-trivy (security scanner)

  5. Persistent Storage Verification

  oc get pvc -n harbor

  5 PVCs successfully bound to NFS:
  - harbor-registry: 50Gi
  - database-data-harbor-database-0: 5Gi
  - data-harbor-redis-0: 2Gi
  - data-harbor-trivy-0: 5Gi
  - harbor-jobservice: 1Gi

  NFS directories created:
  ls -la /exports/harbor/

  6. OpenShift Route Configuration

  Initial attempt (failed):
  oc create route edge harbor --service=harbor --hostname=harbor.apps.lab.ocp.lan --port=80 -n harbor

  Issue: Port mismatch - service uses named port "http" not numeric 80

  Corrected command:
  oc delete route harbor -n harbor
  oc create route edge harbor --service=harbor --hostname=harbor.apps.lab.ocp.lan -n harbor

  Key learning: Let OpenShift auto-detect service ports (works better with named ports)

  Route details:
  - Type: Edge (TLS termination at route)
  - Hostname: harbor.apps.lab.ocp.lan
  - Backend: harbor service port 80 → targetPort 8080
  - TLS: Auto-generated by OpenShift

  7. Access Configuration

  External access via HAProxy:
  Browser → HAProxy (192.168.1.238) → Router pods (192.168.22.201/202) → Harbor Service → Harbor pods

  Credentials:
  - URL: https://harbor.apps.lab.ocp.lan
  - Username: admin
  - Password: Harbor12345

  Key Learnings

  Production Best Practices

  1. OpenShift vs Kubernetes Security:
    - OpenShift enforces stricter SCCs than vanilla Kubernetes
    - Each namespace gets a UID range (prevents privilege escalation)
    - Helm charts from public repos often need SCC adjustments
  2. Helm Chart Troubleshooting:
    - Always use --dry-run --debug before deploying
    - Explore values file with helm show values
    - Check chart compatibility with OpenShift (look for SCC settings)
  3. Service Port Configuration:
    - Named ports (e.g., "http") vs numeric ports
    - OpenShift Routes work better with auto-detected ports
    - Service targetPort vs container port mapping
  4. Storage Planning:
    - Calculate based on: number of images × average size × versions
    - Include buffer (20-30%) for growth
    - Monitor usage: df -h /exports/harbor/
  5. Troubleshooting Methodology:
    - Check pods: oc get pods
    - Check events: oc get events --sort-by='.lastTimestamp'
    - Describe resources: oc describe pod/replicaset/deployment
    - Check logs: oc logs <pod>
    - Verify networking: endpoints, services, routes

  SCC Decision Matrix

  | SCC Type      | Use Case           | Security Level | Harbor Compatible              |
  |---------------|--------------------|----------------|--------------------------------|
  | restricted-v2 | Default            | High           | ❌ No (UID range enforced)      |
  | anyuid        | Custom UIDs needed | Medium         | ⚠️ Partial (seccomp conflicts) |
  | privileged    | Full compatibility | Low            | ✅ Yes                          |

  For Harbor: Used privileged SCC for simplicity in learning environment. Production alternative: rebuild images with OpenShift UIDs.

  Helm Values Customization

  What we changed from defaults:
  - expose.type: ingress → clusterIP
  - expose.tls.enabled: true → false (Route handles TLS)
  - persistence.storageClass: default → nfs-harbor
  - persistence.*.size: Adjusted to fit available storage
  - trivy.enabled: true (security scanning)
  - notary.enabled: false (image signing deferred to Phase 2)
  - metrics.enabled: false (Prometheus integration later)

  Commands Reference

  Check Harbor status

  oc get pods -n harbor
  oc get pvc -n harbor
  oc get route -n harbor

  Access Harbor

  curl -k https://harbor.apps.lab.ocp.lan

  View logs

  oc logs -n harbor deployment/harbor-core
  oc logs -n harbor harbor-database-0

  Restart Harbor components

  oc rollout restart deployment -n harbor
  oc rollout restart statefulset -n harbor

  Check SCC

  oc describe scc privileged
  oc get rolebinding -n harbor | grep scc

  Issues Encountered

  Issue #1: Helm Chart Route Type Incompatibility

  - Error: YAML parse error on harbor/templates/gateway-apis/route.yaml
  - Root Cause: Harbor's route: refers to Gateway API HTTPRoute, not OpenShift Route
  - Resolution: Changed expose.type from route to clusterIP
  - Time to Resolve: 30 minutes

  Issue #2: Security Context Constraints Blocking Pod Creation

  - Error: Pods forbidden - unable to validate against any security context constraint
  - Root Cause: Harbor UIDs (10000, 999) outside OpenShift namespace UID range
  - Resolution: Applied privileged SCC to default service account
  - Time to Resolve: 60 minutes
  - Key Commands:
  oc adm policy add-scc-to-user privileged -z default -n harbor
  helm uninstall harbor -n harbor
  helm install harbor harbor/harbor --namespace harbor --values values-openshift.yaml

  Issue #3: Route Port Mapping

  - Error: Route created but endpoints showed
  - Root Cause: Specified --port=80 but service uses named port "http"
  - Resolution: Recreated route without port specification (auto-detect)
  - Time to Resolve: 15 minutes

  Files Created/Modified

  On ocp-svc:
  - /root/platform-gitops/components/harbor/values-openshift.yaml - Harbor Helm values
  - /root/platform-gitops/components/harbor/values.yaml - Initial attempt (superseded)

  In OpenShift:
  - Namespace: harbor
  - Helm release: harbor
  - Route: harbor.apps.lab.ocp.lan
  - SCC binding: system:serviceaccount:harbor:default → privileged

  On NFS server:
  - /exports/harbor/harbor-* - 5 PVC directories (64Gi allocated)

  Cluster State

  Namespaces

  - harbor - Harbor registry (newly created)
  - openshift-gitops - ArgoCD (from Session 001)
  - nfs-provisioner - NFS dynamic provisioner (from Session 002)

  Storage

  - Total allocated to Harbor: ~64Gi
  - Available on NFS: 104Gi → ~40Gi remaining
  - StorageClass: nfs-harbor (default)

  Access Points

  - Harbor UI: https://harbor.apps.lab.ocp.lan
  - OpenShift Console: https://console-openshift-console.apps.lab.ocp.lan
  - ArgoCD: https://openshift-gitops-server-openshift-gitops.apps.lab.ocp.lan

  Next Steps

  Immediate (Session 004)

  1. Create Harbor projects (library, platform, apps)
  2. Configure Harbor security scanning policies
  3. Test image push/pull workflow
  4. Set up image replication (if needed)

  Upcoming

  1. Week 2 Day 1: Deploy HashiCorp Vault (HA with Raft storage)
  2. Week 2 Day 2: External Secrets Operator integration
  3. Week 2 Day 3: Move Harbor password to Vault
  4. Week 2 Day 4-5: Tekton CI/CD pipelines with Harbor integration

  Production Readiness Checklist

  For moving Harbor to production:
  - Move admin password to Vault
  - Configure LDAP/OIDC authentication
  - Set up RBAC with project-specific permissions
  - Enable and configure image scanning policies
  - Implement image retention policies
  - Set up Harbor HA (multiple replicas)
  - Configure backup strategy for database
  - Monitor storage usage and set up alerts
  - Document DR procedures
  - Consider: Rebuild images with OpenShift UIDs instead of privileged SCC

  ---
  Session End: Harbor successfully deployed and accessible ✅Progress: Phase 1 Day 1 complete (~20% of overall platform build)
